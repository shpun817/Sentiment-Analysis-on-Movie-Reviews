---
title: "ISOM3390 Final Project"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, tidy = TRUE)
```

Before proceeding to the exercise, make sure the `tidyverse` is installed in your lab computer.

```{r}
library(tidyverse)
library(rvest)
library(RSelenium)
library(tidytext)
```

First, r un the command
java -Dwebdriver.chrome.driver=chromedriver.exe -jar selenium-server-standalone-3.141.59.jar
to start the server.

```{r}
# Connect to the running server
remDr <- remoteDriver(remoteServerAddr = "localhost", port = 4445L,
browserName = "chrome") # "firefox", "internet explorer", "iphone", etc.
#str(remDr, max.level = 1)

# Start the browser
remDr$open(silent = TRUE)

# Get the status of the server
remDr$getStatus() %>% str()

# Navigate to the url
remDr$navigate("https://www.imdb.com/chart/moviemeter?sort=rk,asc&mode=simple&page=1")
```

For each movie, control the server to click into the movie title and collect necessary data

```{r}
# First, create a tibble with movie titles and their hyperlinks
page_source <- remDr$getPageSource()[[1]] %>% read_html()
movies_table <- page_source %>% html_node(".lister-list")
movies_titles <- movies_table %>% html_nodes("a") %>% html_text(trim = TRUE) %>% .[seq(2, 200, 2)]
movies_urls <- movies_table %>% html_nodes("a") %>% html_attr("href") %>% .[seq(2, 200, 2)] %>% str_c("https://www.imdb.com", .)

movies <- tibble(title = movies_titles, url = movies_urls)
movies %>% head
```

```{r}
# Create a tibble to store user reviews
reviews <- tibble(movie = character(), rating = numeric(), review_header = character(), review = character())

# Next, use a for loop along the movies tibble to collect 100 user reviews for each movie
for (i in seq_along(movies$title)) {
#for (i in 1:3) { 
  # Extract the id that IMDb assigns to each movie
  movie_id <- movies$url[i] %>% str_extract("/title/.+/")
  
  # Navigate to the user reviews page
  reviews_url <- movie_id %>% str_c("https://www.imdb.com", ., "reviews?ref_=tt_urv")
  remDr$navigate(reviews_url)
  
  Sys.sleep(3)
  
  # Locate the hide spoilers checkbox
  hideSpoilers <- remDr$findElement(using = "css", value = ".lister-widget-sprite.lister-checkbox")
  #class(hideSpoilers)
  hideSpoilers$clickElement() # Tick the checkbox to hide spoilers
  
  Sys.sleep(3)
  
  # Find the total number of reviews
  page_source <- remDr$getPageSource()[[1]] %>% read_html()
  num_reviews <- page_source %>% html_node(".lister") %>% html_node(".header") %>% html_nodes("span") %>% .[1] %>% html_text(trim = TRUE) %>% str_extract(".+ ") %>% str_sub(end = -2) %>% gsub(",", "", .) %>% as.numeric()
  
  if (num_reviews <= 0) {
    next
  }
  
  # Determine the number of clicks on the show more button.
  # At start the page shows 25 reviews (or less).
  # Each click loads 25 more.
  num_clicks <- 3
  if (num_reviews <= 25) {
    num_clicks <- 0
  } else if (num_reviews <= 50) {
    num_clicks <- 1
  } else if (num_reviews <= 75) {
    num_clicks <- 2
  } else {
    num_clicks <- 3
  }
  
  if (num_clicks > 0) {
    # Perform the determined number of clicks
    for (click in 1:num_clicks) {
      # Locate the loadmore button
      loadMore <- remDr$findElement(using = "css", value = ".ipl-load-more__button")
      loadMore$clickElement()
      Sys.sleep(3) # Wait for loading
    }
  }
  
  # Expand all long review
  expanders <- remDr$findElements(using = "css", value = ".expander-icon-wrapper.show-more__control")
  if (expanders %>% length > 0) {
    for (j in seq_along(expanders)) {
      expanders[[j]]$clickElement()
    }
  }
  
  # Locate the list containing all user reviews
  page_source <- remDr$getPageSource()[[1]] %>% read_html()
  whole_list <- page_source %>% html_nodes(".lister-list")
  if (whole_list %>% length == 0) { # List not found
    next
  }
  whole_list <- whole_list[1] %>% html_nodes(".lister-item.mode-detail.imdb-user-review.collapsable")
  
  if (whole_list %>% length == 0) { # No review elements in the list
    next
  }
  
  # For each piece of user review, collect the rating and the review
  review_count <- 1 # when this count reaches 101, break the loop
  for (j in seq_along(whole_list)) {
    if (review_count >= 101) {
      break
    }
    
    # Obtain the rating
    rating <- NA
    # Check if a rating exists
    if (whole_list[j] %>% html_nodes(".rating-other-user-rating") %>% length > 0) {
      rating <- whole_list[j] %>% html_node(".rating-other-user-rating") %>% html_node("span") %>% html_text(trim = TRUE) %>% as.numeric()
    }
    
    # Obtain the review header
    header <- NA
    # Check if a header exists
    if (whole_list[j] %>% html_nodes(".title") %>% length > 0) {
      header <- whole_list[j] %>% html_node(".title") %>% html_text(trim = TRUE)
    }
    
    # Obtain the review content
    content <- NA
    # Check if content exists (play safe)
    if (whole_list[j] %>% html_nodes(".text.show-more__control") %>% length > 0) {
      content <- whole_list[j] %>% html_node(".text.show-more__control") %>% html_text(trim = TRUE)
    }
    
    reviews <- reviews %>% add_row(movie = movies$title[i], rating = rating, review_header = header, review = content)
    
    review_count <- review_count + 1
  }
  
}

```

Write the reviews tibble into a csv file.

```{r}
reviews %>% write.csv("reviews.csv")
```

Read the reviews from the csv file.

```{r}
reviews <- read.csv("reviews.csv")
```


There are 4334 positive reviews and 2756 negative reviews. Let's sample 2500 Positive reviews and 2500 negative reviews and store it to reviews_sample

```{r}
reviews_pos <- reviews %>% filter(rating >= 6) %>% head(2500)
reviews_neg <- reviews %>% filter(rating <= 5) %>% head(2500)

reviews_sample <- rbind(reviews_pos, reviews_neg)

reviews_sample
```



Now, we have to do some preprocessing. Let's tokenize and remove the stop-word in the review

```{r}
reviews_sample_token <- reviews_sample %>% unnest_tokens(word,review) %>% filter(!str_detect(word, "^[0-9]*$"))
reviews_sample_token
reviews_sample_no_stopword <- reviews_sample_token %>% anti_join(stop_words, by= "word")
reviews_sample_no_stopword
reviews_sample_bing <- reviews_sample_no_stopword %>% inner_join(get_sentiments("bing"), by= "word")
reviews_sample_bing
```

We have a bag of word now. Let's predict the sentiment according to those word, and evaluate the outcomes by contrasting with actual rating.
Since some of the reviews just contain a bunch of stopwords, those reviews is removed in the preprocessing.

```{r}
reviews_predict <- reviews_sample_bing %>% count(X, movie, review_header, rating, sentiment) %>% pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% mutate(sentiment = round(positive * 10 / (positive + negative)) , diff = sentiment - rating  )

reviews_predict
```

Let's evaluate the outcomes by contrasting with actual rating.
677 reviews are perfectly predicted.

```{r}
reviews_predict %>% filter(diff == 0) %>% inner_join(reviews, by= c("X", "movie",  "review_header", "rating") ) %>% select("X","review", "rating", "negative", "positive", "sentiment", "diff"  ) 
```


```{r}
reviews_predict %>% filter(diff < -5) %>% inner_join(reviews, by= c("X", "movie",  "review_header", "rating") ) %>% select("X","review", "rating", "negative", "positive", "sentiment", "diff"  ) 
```

Let's evaluate it with the ROC score. Here, we do a binary classification. If the predict score is higher than 6, then it is "positive", otherwise, it is "negative". 

```{r}
library(ROCR)
pred <- prediction(reviews_predict$sentiment, ifelse(reviews_predict$rating>5,1,0))
perf <- performance(pred,"tpr","fpr")
plot(perf,colorize=TRUE)

```

Evaluation

Since many words are not exist in the RING lexicon (either the word is neutral).
Words have different meaning in different context. 


```{r}
freq_words <- reviews_sample_bing %>% select("word" , "sentiment" , "rating") %>% group_by(word , sentiment, rating) %>% summarise("count" = n())
freq_words <- freq_words[order(freq_words$count , decreasing = TRUE),]
```

The 5 most commonly-used negative word.

```{r}
freq_words_neg <-freq_words %>% filter(sentiment == "negative") %>% select("word" , "sentiment" , "count") %>% summarise("sum" = sum(count))
freq_words_neg <- freq_words_neg[order(freq_words_neg$sum , decreasing = TRUE),]
freq_words_neg <- freq_words_neg %>% head(5)
freq_words_neg
```

The 5 most commonly-used positive word.

```{r}
freq_words_pos <- freq_words %>% filter(sentiment == "positive") %>% select("word" , "sentiment" , "count") %>% summarise("sum" = sum(count))
freq_words_pos <- freq_words_pos[order(freq_words_pos$sum , decreasing = TRUE),]
freq_words_pos <- freq_words_pos %>% head(5)
freq_words_pos
```
Below are the graph

```{r}

data <- freq_words %>% inner_join(freq_words_pos, by="word", "sentiment") %>% mutate(weight = count / sum)
#data <- freq_words %>% filter(word == freq_words_pos[1,1]) %>% mutate(weight = count / freq_words_pos[[1,3]])
data
ggplot(data, aes(rating, weight)) + geom_point() + geom_line() + theme_bw() + facet_wrap(~ word, ncol = 3, scales = "free_x")
```



```{r}
data <- freq_words %>% inner_join(freq_words_neg, by="word", "sentiment") %>% mutate(weight = count / sum)
#data <- freq_words %>% filter(word == freq_words_pos[1,1]) %>% mutate(weight = count / freq_words_pos[[1,3]])
data
ggplot(data, aes(rating, weight)) + geom_point() + geom_line() + theme_bw() + facet_wrap(~ word, ncol = 3, scales = "free_x")
```


